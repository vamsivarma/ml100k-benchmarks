{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "H2O AutoML with ml-100k.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JR2okAZ7jzrt"
      },
      "source": [
        "## Setting up H2O AutoML"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNXgWdBkdGPO",
        "outputId": "46e5152f-0996-4b4f-81a3-61b4424a0c19"
      },
      "source": [
        "! apt-get install default-jre\n",
        "!java -version"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "default-jre is already the newest version (2:1.11-68ubuntu1~18.04.1).\n",
            "default-jre set to manually installed.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 16 not upgraded.\n",
            "openjdk version \"11.0.9.1\" 2020-11-04\n",
            "OpenJDK Runtime Environment (build 11.0.9.1+1-Ubuntu-0ubuntu1.18.04)\n",
            "OpenJDK 64-Bit Server VM (build 11.0.9.1+1-Ubuntu-0ubuntu1.18.04, mixed mode, sharing)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihgRSoHtdw2h",
        "outputId": "3d68a602-1de3-432b-fbc0-1d50f82b1b70"
      },
      "source": [
        "! pip install h2o"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting h2o\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/d1/9edb2359afa29049bb6e75f9a673bb68c897e7f3e6238ffb77ba9eddf04b/h2o-3.32.0.3.tar.gz (164.6MB)\n",
            "\u001b[K     |████████████████████████████████| 164.6MB 80kB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from h2o) (2.23.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from h2o) (0.8.7)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from h2o) (0.16.0)\n",
            "Collecting colorama>=0.3.8\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->h2o) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->h2o) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->h2o) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->h2o) (3.0.4)\n",
            "Building wheels for collected packages: h2o\n",
            "  Building wheel for h2o (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for h2o: filename=h2o-3.32.0.3-py2.py3-none-any.whl size=164649662 sha256=68c6cf623e5c66454e425b2edf580e697656289bc600bc5c60bffdbbfab1f9ac\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/fd/63/96d322a27867a81a2904172a75aed5241913d603a4b8c4b277\n",
            "Successfully built h2o\n",
            "Installing collected packages: colorama, h2o\n",
            "Successfully installed colorama-0.4.4 h2o-3.32.0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "yT17HSz7cT4i",
        "outputId": "43b20e05-0224-4049-9a17-52cc6e69e4d7"
      },
      "source": [
        "import h2o\n",
        "from h2o.automl import H2OAutoML\n",
        "h2o.init()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.\n",
            "Attempting to start a local H2O server...\n",
            "  Java Version: openjdk version \"11.0.9.1\" 2020-11-04; OpenJDK Runtime Environment (build 11.0.9.1+1-Ubuntu-0ubuntu1.18.04); OpenJDK 64-Bit Server VM (build 11.0.9.1+1-Ubuntu-0ubuntu1.18.04, mixed mode, sharing)\n",
            "  Starting server from /usr/local/lib/python3.6/dist-packages/h2o/backend/bin/h2o.jar\n",
            "  Ice root: /tmp/tmpliscoi3q\n",
            "  JVM stdout: /tmp/tmpliscoi3q/h2o_unknownUser_started_from_python.out\n",
            "  JVM stderr: /tmp/tmpliscoi3q/h2o_unknownUser_started_from_python.err\n",
            "  Server is running at http://127.0.0.1:54321\n",
            "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n",
              "<td>03 secs</td></tr>\n",
              "<tr><td>H2O_cluster_timezone:</td>\n",
              "<td>Etc/UTC</td></tr>\n",
              "<tr><td>H2O_data_parsing_timezone:</td>\n",
              "<td>UTC</td></tr>\n",
              "<tr><td>H2O_cluster_version:</td>\n",
              "<td>3.32.0.3</td></tr>\n",
              "<tr><td>H2O_cluster_version_age:</td>\n",
              "<td>22 days </td></tr>\n",
              "<tr><td>H2O_cluster_name:</td>\n",
              "<td>H2O_from_python_unknownUser_m0hbxk</td></tr>\n",
              "<tr><td>H2O_cluster_total_nodes:</td>\n",
              "<td>1</td></tr>\n",
              "<tr><td>H2O_cluster_free_memory:</td>\n",
              "<td>3.180 Gb</td></tr>\n",
              "<tr><td>H2O_cluster_total_cores:</td>\n",
              "<td>2</td></tr>\n",
              "<tr><td>H2O_cluster_allowed_cores:</td>\n",
              "<td>2</td></tr>\n",
              "<tr><td>H2O_cluster_status:</td>\n",
              "<td>accepting new members, healthy</td></tr>\n",
              "<tr><td>H2O_connection_url:</td>\n",
              "<td>http://127.0.0.1:54321</td></tr>\n",
              "<tr><td>H2O_connection_proxy:</td>\n",
              "<td>{\"http\": null, \"https\": null}</td></tr>\n",
              "<tr><td>H2O_internal_security:</td>\n",
              "<td>False</td></tr>\n",
              "<tr><td>H2O_API_Extensions:</td>\n",
              "<td>Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
              "<tr><td>Python_version:</td>\n",
              "<td>3.6.9 final</td></tr></table></div>"
            ],
            "text/plain": [
              "--------------------------  ------------------------------------------------------------------\n",
              "H2O_cluster_uptime:         03 secs\n",
              "H2O_cluster_timezone:       Etc/UTC\n",
              "H2O_data_parsing_timezone:  UTC\n",
              "H2O_cluster_version:        3.32.0.3\n",
              "H2O_cluster_version_age:    22 days\n",
              "H2O_cluster_name:           H2O_from_python_unknownUser_m0hbxk\n",
              "H2O_cluster_total_nodes:    1\n",
              "H2O_cluster_free_memory:    3.180 Gb\n",
              "H2O_cluster_total_cores:    2\n",
              "H2O_cluster_allowed_cores:  2\n",
              "H2O_cluster_status:         accepting new members, healthy\n",
              "H2O_connection_url:         http://127.0.0.1:54321\n",
              "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
              "H2O_internal_security:      False\n",
              "H2O_API_Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4\n",
              "Python_version:             3.6.9 final\n",
              "--------------------------  ------------------------------------------------------------------"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXw36lQGcT4k"
      },
      "source": [
        "### Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4ege83ecT4l",
        "outputId": "e0eb6a70-6651-49fd-b134-91122dd641fa"
      },
      "source": [
        "# Use local data file or download from GitHub\n",
        "import os\n",
        "docker_data_path = \"ratings_new.csv\"\n",
        "if os.path.isfile(docker_data_path):\n",
        "  data_path = docker_data_path\n",
        "else:\n",
        "  data_path = \"ratings_new.csv\"\n",
        "\n",
        "\n",
        "# Load data into H2O\n",
        "df = h2o.import_file(data_path)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xiTIjOvcT4l"
      },
      "source": [
        "Let's take a look at the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "BZinPQZecT4l",
        "outputId": "c0a4afcf-5bd5-471e-97f8-14d79dbf2da6"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Rows:100836\n",
            "Cols:3\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table>\n",
              "<thead>\n",
              "<tr><th>       </th><th>userId            </th><th>movieId          </th><th>rating            </th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>type   </td><td>int               </td><td>int              </td><td>real              </td></tr>\n",
              "<tr><td>mins   </td><td>1.0               </td><td>1.0              </td><td>0.5               </td></tr>\n",
              "<tr><td>mean   </td><td>326.12756356856625</td><td>19435.29571779919</td><td>3.5015569836169598</td></tr>\n",
              "<tr><td>maxs   </td><td>610.0             </td><td>193609.0         </td><td>5.0               </td></tr>\n",
              "<tr><td>sigma  </td><td>182.618491463499  </td><td>35530.98719870016</td><td>1.0425292390606347</td></tr>\n",
              "<tr><td>zeros  </td><td>0                 </td><td>0                </td><td>0                 </td></tr>\n",
              "<tr><td>missing</td><td>0                 </td><td>0                </td><td>0                 </td></tr>\n",
              "<tr><td>0      </td><td>1.0               </td><td>1.0              </td><td>4.0               </td></tr>\n",
              "<tr><td>1      </td><td>1.0               </td><td>3.0              </td><td>4.0               </td></tr>\n",
              "<tr><td>2      </td><td>1.0               </td><td>6.0              </td><td>4.0               </td></tr>\n",
              "<tr><td>3      </td><td>1.0               </td><td>47.0             </td><td>5.0               </td></tr>\n",
              "<tr><td>4      </td><td>1.0               </td><td>50.0             </td><td>5.0               </td></tr>\n",
              "<tr><td>5      </td><td>1.0               </td><td>70.0             </td><td>3.0               </td></tr>\n",
              "<tr><td>6      </td><td>1.0               </td><td>101.0            </td><td>5.0               </td></tr>\n",
              "<tr><td>7      </td><td>1.0               </td><td>110.0            </td><td>4.0               </td></tr>\n",
              "<tr><td>8      </td><td>1.0               </td><td>151.0            </td><td>5.0               </td></tr>\n",
              "<tr><td>9      </td><td>1.0               </td><td>157.0            </td><td>5.0               </td></tr>\n",
              "</tbody>\n",
              "</table>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIfcLrXjcT4m"
      },
      "source": [
        "Identify the response column and save the column name as `y`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06S3VJiTcT4m"
      },
      "source": [
        "y = \"rating\""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m41KPkcQcT4m"
      },
      "source": [
        "Lastly, let's split the data into two frames, a `train` (80%) and a `test` frame (20%).  The `test` frame will be used to score the leaderboard and to demonstrate how to generate predictions using an AutoML leader model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nq3iUHvcT4n"
      },
      "source": [
        "splits = df.split_frame(ratios = [0.8], seed = 1)\n",
        "train = splits[0]\n",
        "test = splits[1]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yhc6C9T9cT4n"
      },
      "source": [
        "## Run AutoML \n",
        "\n",
        "Run AutoML, stopping after 60 seconds.  The `max_runtime_secs` argument provides a way to limit the AutoML run by time.  When using a time-limited stopping criterion, the number of models train will vary between runs.  If different hardware is used or even if the same machine is used but the available compute resources on that machine are not the same between runs, then AutoML may be able to train more models on one run vs another. \n",
        "\n",
        "The `test` frame is passed explicitly to the `leaderboard_frame` argument here, which means that instead of using cross-validated metrics, we use test set metrics for generating the leaderboard."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqzoGNJ6cT4n",
        "outputId": "3d642834-e203-4f21-efca-43408b839fa1"
      },
      "source": [
        "aml = H2OAutoML(max_runtime_secs = 60, seed = 1, project_name = \"ml100k_lb_frame\")\n",
        "aml.train(y = y, training_frame = train, leaderboard_frame = test)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AutoML progress: |████████████████████████████████████████████████████████| 100%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJG_QKS9cT4o",
        "outputId": "534c6708-f2ed-4025-ecb5-7e2b4f4dbd9d"
      },
      "source": [
        "aml2 = H2OAutoML(max_runtime_secs = 60, seed = 1, project_name = \"ml100k_full_data\")\n",
        "aml2.train(y = y, training_frame = df)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AutoML progress: |████████████████████████████████████████████████████████| 100%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGMYbaLpcT4o"
      },
      "source": [
        "*Note: We specify a `project_name` here for clarity.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBtMkiPxcT4p"
      },
      "source": [
        "## Leaderboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "iMJNZHwXcT4p",
        "outputId": "5a630ced-99d2-450f-c5fc-81bdb1e543de"
      },
      "source": [
        "aml.leaderboard.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table>\n",
              "<thead>\n",
              "<tr><th>model_id                                           </th><th style=\"text-align: right;\">  mean_residual_deviance</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">     mse</th><th style=\"text-align: right;\">     mae</th><th style=\"text-align: right;\">   rmsle</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>StackedEnsemble_AllModels_AutoML_20210115_191607   </td><td style=\"text-align: right;\">                0.858878</td><td style=\"text-align: right;\">0.926757</td><td style=\"text-align: right;\">0.858878</td><td style=\"text-align: right;\">0.726354</td><td style=\"text-align: right;\">0.247382</td></tr>\n",
              "<tr><td>StackedEnsemble_BestOfFamily_AutoML_20210115_191607</td><td style=\"text-align: right;\">                0.867075</td><td style=\"text-align: right;\">0.931168</td><td style=\"text-align: right;\">0.867075</td><td style=\"text-align: right;\">0.723846</td><td style=\"text-align: right;\">0.24995 </td></tr>\n",
              "<tr><td>XGBoost_grid__1_AutoML_20210115_191607_model_1     </td><td style=\"text-align: right;\">                0.877164</td><td style=\"text-align: right;\">0.93657 </td><td style=\"text-align: right;\">0.877164</td><td style=\"text-align: right;\">0.731772</td><td style=\"text-align: right;\">0.251504</td></tr>\n",
              "<tr><td>GBM_4_AutoML_20210115_191607                       </td><td style=\"text-align: right;\">                1.03747 </td><td style=\"text-align: right;\">1.01856 </td><td style=\"text-align: right;\">1.03747 </td><td style=\"text-align: right;\">0.811097</td><td style=\"text-align: right;\">0.271089</td></tr>\n",
              "<tr><td>GBM_3_AutoML_20210115_191607                       </td><td style=\"text-align: right;\">                1.04534 </td><td style=\"text-align: right;\">1.02242 </td><td style=\"text-align: right;\">1.04534 </td><td style=\"text-align: right;\">0.814428</td><td style=\"text-align: right;\">0.271873</td></tr>\n",
              "<tr><td>GBM_5_AutoML_20210115_191607                       </td><td style=\"text-align: right;\">                1.05093 </td><td style=\"text-align: right;\">1.02515 </td><td style=\"text-align: right;\">1.05093 </td><td style=\"text-align: right;\">0.816439</td><td style=\"text-align: right;\">0.272812</td></tr>\n",
              "<tr><td>GBM_grid__1_AutoML_20210115_191607_model_1         </td><td style=\"text-align: right;\">                1.05216 </td><td style=\"text-align: right;\">1.02575 </td><td style=\"text-align: right;\">1.05216 </td><td style=\"text-align: right;\">0.816484</td><td style=\"text-align: right;\">0.272803</td></tr>\n",
              "<tr><td>GBM_2_AutoML_20210115_191607                       </td><td style=\"text-align: right;\">                1.05791 </td><td style=\"text-align: right;\">1.02855 </td><td style=\"text-align: right;\">1.05791 </td><td style=\"text-align: right;\">0.818203</td><td style=\"text-align: right;\">0.273351</td></tr>\n",
              "<tr><td>GBM_1_AutoML_20210115_191607                       </td><td style=\"text-align: right;\">                1.07241 </td><td style=\"text-align: right;\">1.03557 </td><td style=\"text-align: right;\">1.07241 </td><td style=\"text-align: right;\">0.823277</td><td style=\"text-align: right;\">0.274831</td></tr>\n",
              "<tr><td>GLM_1_AutoML_20210115_191607                       </td><td style=\"text-align: right;\">                1.08146 </td><td style=\"text-align: right;\">1.03993 </td><td style=\"text-align: right;\">1.08146 </td><td style=\"text-align: right;\">0.827454</td><td style=\"text-align: right;\">0.275764</td></tr>\n",
              "</tbody>\n",
              "</table>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eccjKspAcT4p"
      },
      "source": [
        "Now we will view a snapshot of the top models.  Here we should see the two Stacked Ensembles at or near the top of the leaderboard.  Stacked Ensembles can almost always outperform a single model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "j4R6Tvi9cT4q",
        "outputId": "d98efe95-25bb-4c01-ce44-6af3bf64b7cf"
      },
      "source": [
        "aml2.leaderboard.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table>\n",
              "<thead>\n",
              "<tr><th>model_id                                           </th><th style=\"text-align: right;\">  mean_residual_deviance</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">     mse</th><th style=\"text-align: right;\">     mae</th><th style=\"text-align: right;\">   rmsle</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>StackedEnsemble_AllModels_AutoML_20210115_191757   </td><td style=\"text-align: right;\">                0.850114</td><td style=\"text-align: right;\">0.922016</td><td style=\"text-align: right;\">0.850114</td><td style=\"text-align: right;\">0.71688 </td><td style=\"text-align: right;\">0.247793</td></tr>\n",
              "<tr><td>StackedEnsemble_BestOfFamily_AutoML_20210115_191757</td><td style=\"text-align: right;\">                0.863591</td><td style=\"text-align: right;\">0.929296</td><td style=\"text-align: right;\">0.863591</td><td style=\"text-align: right;\">0.722773</td><td style=\"text-align: right;\">0.2496  </td></tr>\n",
              "<tr><td>XGBoost_grid__1_AutoML_20210115_191757_model_1     </td><td style=\"text-align: right;\">                0.872988</td><td style=\"text-align: right;\">0.934338</td><td style=\"text-align: right;\">0.872988</td><td style=\"text-align: right;\">0.730253</td><td style=\"text-align: right;\">0.251222</td></tr>\n",
              "<tr><td>GBM_4_AutoML_20210115_191757                       </td><td style=\"text-align: right;\">                1.03387 </td><td style=\"text-align: right;\">1.0168  </td><td style=\"text-align: right;\">1.03387 </td><td style=\"text-align: right;\">0.808668</td><td style=\"text-align: right;\">0.27126 </td></tr>\n",
              "<tr><td>GBM_grid__1_AutoML_20210115_191757_model_1         </td><td style=\"text-align: right;\">                1.05042 </td><td style=\"text-align: right;\">1.0249  </td><td style=\"text-align: right;\">1.05042 </td><td style=\"text-align: right;\">0.815446</td><td style=\"text-align: right;\">0.273121</td></tr>\n",
              "<tr><td>GBM_1_AutoML_20210115_191757                       </td><td style=\"text-align: right;\">                1.05739 </td><td style=\"text-align: right;\">1.02829 </td><td style=\"text-align: right;\">1.05739 </td><td style=\"text-align: right;\">0.817521</td><td style=\"text-align: right;\">0.273793</td></tr>\n",
              "<tr><td>GBM_5_AutoML_20210115_191757                       </td><td style=\"text-align: right;\">                1.06057 </td><td style=\"text-align: right;\">1.02984 </td><td style=\"text-align: right;\">1.06057 </td><td style=\"text-align: right;\">0.819031</td><td style=\"text-align: right;\">0.274274</td></tr>\n",
              "<tr><td>GBM_3_AutoML_20210115_191757                       </td><td style=\"text-align: right;\">                1.06242 </td><td style=\"text-align: right;\">1.03074 </td><td style=\"text-align: right;\">1.06242 </td><td style=\"text-align: right;\">0.81946 </td><td style=\"text-align: right;\">0.274269</td></tr>\n",
              "<tr><td>GBM_2_AutoML_20210115_191757                       </td><td style=\"text-align: right;\">                1.0743  </td><td style=\"text-align: right;\">1.03648 </td><td style=\"text-align: right;\">1.0743  </td><td style=\"text-align: right;\">0.823384</td><td style=\"text-align: right;\">0.275606</td></tr>\n",
              "<tr><td>GLM_1_AutoML_20210115_191757                       </td><td style=\"text-align: right;\">                1.08424 </td><td style=\"text-align: right;\">1.04127 </td><td style=\"text-align: right;\">1.08424 </td><td style=\"text-align: right;\">0.830256</td><td style=\"text-align: right;\">0.276578</td></tr>\n",
              "</tbody>\n",
              "</table>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOhuSzK3cT4q"
      },
      "source": [
        "## Predict Using Leader Model\n",
        "\n",
        "If you need to generate predictions on a test set, you can make predictions on the `\"H2OAutoML\"` object directly, or on the leader model object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "CGejF7o0cT4r",
        "outputId": "d26d6baf-e31c-4ef6-f52b-f2b7ccf1bdc6"
      },
      "source": [
        "pred = aml.predict(test)\n",
        "pred.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "stackedensemble prediction progress: |████████████████████████████████████| 100%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table>\n",
              "<thead>\n",
              "<tr><th style=\"text-align: right;\">  predict</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td style=\"text-align: right;\">  4.24333</td></tr>\n",
              "<tr><td style=\"text-align: right;\">  3.9449 </td></tr>\n",
              "<tr><td style=\"text-align: right;\">  4.31107</td></tr>\n",
              "<tr><td style=\"text-align: right;\">  4.0852 </td></tr>\n",
              "<tr><td style=\"text-align: right;\">  4.02601</td></tr>\n",
              "<tr><td style=\"text-align: right;\">  4.38628</td></tr>\n",
              "<tr><td style=\"text-align: right;\">  4.20321</td></tr>\n",
              "<tr><td style=\"text-align: right;\">  4.4545 </td></tr>\n",
              "<tr><td style=\"text-align: right;\">  4.38827</td></tr>\n",
              "<tr><td style=\"text-align: right;\">  4.52566</td></tr>\n",
              "</tbody>\n",
              "</table>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ADkitqucT4s"
      },
      "source": [
        "If needed, the standard `model_performance()` method can be applied to the AutoML leader model and a test set to generate an H2O model performance object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWuRcbh3cT4s",
        "outputId": "0bd01d45-3c8e-4f36-b39b-39eeff6adcfb"
      },
      "source": [
        "perf = aml.leader.model_performance(test)\n",
        "perf"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ModelMetricsRegressionGLM: stackedensemble\n",
            "** Reported on test data. **\n",
            "\n",
            "MSE: 0.8588780678874272\n",
            "RMSE: 0.9267567468799065\n",
            "MAE: 0.7263537121139809\n",
            "RMSLE: 0.24738164203141583\n",
            "R^2: 0.20690125290850947\n",
            "Mean Residual Deviance: 0.8588780678874272\n",
            "Null degrees of freedom: 20192\n",
            "Residual degrees of freedom: 20186\n",
            "Null deviance: 21868.68751719775\n",
            "Residual deviance: 17343.324824850817\n",
            "AIC: 54249.32456439552\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    }
  ]
}